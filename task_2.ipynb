{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Generate Sparse Representations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name: Xiaofan Zhang\n",
    "#### Student ID: 28338707\n",
    "\n",
    "Date: 03/06/2018\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include the main libraries you used in your assignment here, e.g.,: \n",
    "* re \n",
    "* os\n",
    "* nltk\n",
    "* nltk.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import FreqDist\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all stopwords\n",
    "# remove words whose frequencies is larger than 132 less than 3\n",
    "# sort the list\n",
    "# add index number behind every tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unigram vocabulary \n",
    "## All raw tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file_path = \"./txt_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+(?:[-']\\w+)?\") \n",
    "def main(file):\n",
    "    \n",
    "    file_object = open(file, \"r\")\n",
    "    lines = file_object.readlines()\n",
    "    \n",
    "    unigram_tokens = []\n",
    "    for line in lines:\n",
    "        line = line.strip().lower()\n",
    "        \n",
    "        token_list = tokenizer.tokenize(line)\n",
    "        for i in range(len(token_list)):\n",
    "            unigram_tokens.append(token_list[i])\n",
    "         \n",
    "    file_object.close()\n",
    "    # delete duplicate tokens\n",
    "    return(set(unigram_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fine',\n",
       " 'nice',\n",
       " 'stages',\n",
       " 'about',\n",
       " 'god',\n",
       " 'is',\n",
       " 'talking',\n",
       " 'too',\n",
       " 'sum',\n",
       " 'wags',\n",
       " 'unique',\n",
       " 'suppose',\n",
       " 'whistle',\n",
       " 'blue',\n",
       " 'gimmicky',\n",
       " 'technologically',\n",
       " \"who's\",\n",
       " 'harmless',\n",
       " 'own',\n",
       " 'right',\n",
       " 'regular',\n",
       " 'm_p_',\n",
       " 'living',\n",
       " 'next',\n",
       " 'each',\n",
       " 'discuss',\n",
       " \"you'll\",\n",
       " 'terms',\n",
       " 'scribble',\n",
       " \"we've\",\n",
       " 'its',\n",
       " 'information',\n",
       " 'pitched',\n",
       " 'chasing',\n",
       " 'thing',\n",
       " 'animal',\n",
       " 'bas',\n",
       " 'technology',\n",
       " 'junky',\n",
       " 'issue',\n",
       " 'personally',\n",
       " 'hit',\n",
       " 'they',\n",
       " 'uh-huh',\n",
       " 'yeah',\n",
       " 'piece',\n",
       " 'greece',\n",
       " 'did',\n",
       " 'draw',\n",
       " 'start',\n",
       " 'supposed',\n",
       " 'sold',\n",
       " 'forever',\n",
       " 'reason',\n",
       " 'health',\n",
       " 'control',\n",
       " 'depends',\n",
       " 'oh',\n",
       " 'even',\n",
       " 'though',\n",
       " 'video',\n",
       " 'chases',\n",
       " 'retailer',\n",
       " 'th',\n",
       " 'view',\n",
       " 'certain',\n",
       " 'pe',\n",
       " 'again',\n",
       " 'sudden',\n",
       " 'doing',\n",
       " 'country',\n",
       " 'standard',\n",
       " 'premium',\n",
       " 'being',\n",
       " 'dunno',\n",
       " 'combine',\n",
       " 'animals',\n",
       " 'come',\n",
       " 'looks',\n",
       " \"i'd\",\n",
       " 'really',\n",
       " 'telephones',\n",
       " 'down',\n",
       " 'personality',\n",
       " 'aware',\n",
       " 'yep',\n",
       " 'received',\n",
       " 'space',\n",
       " 'slipped',\n",
       " 'get',\n",
       " 'eighteen',\n",
       " 'f',\n",
       " 'will',\n",
       " 'natural',\n",
       " 'craig',\n",
       " 'industrial',\n",
       " 'agenda',\n",
       " 'maybe',\n",
       " 'thoughts',\n",
       " 'much',\n",
       " 'charac',\n",
       " 'impressionist',\n",
       " 'want',\n",
       " 'hi',\n",
       " 'um',\n",
       " 'characters',\n",
       " 'andrew',\n",
       " 'ma',\n",
       " \"haven't\",\n",
       " 'people',\n",
       " 'assumption',\n",
       " 'them',\n",
       " 'becomes',\n",
       " 'wondering',\n",
       " 'satellite',\n",
       " 'do',\n",
       " 'background',\n",
       " 'find',\n",
       " 'knew',\n",
       " 'introduce',\n",
       " \"i've\",\n",
       " 'better',\n",
       " 'used',\n",
       " \"tail's\",\n",
       " 'price',\n",
       " 'region',\n",
       " 'habits',\n",
       " 'knows',\n",
       " 'pain',\n",
       " 'l',\n",
       " 'des',\n",
       " 'bit',\n",
       " \"don't\",\n",
       " 'pounds',\n",
       " 'bought',\n",
       " 'fifty',\n",
       " 'idea',\n",
       " 'basically',\n",
       " 'those',\n",
       " 'pretty',\n",
       " 'superb',\n",
       " 'priority',\n",
       " \"family's\",\n",
       " 'dog',\n",
       " 'look',\n",
       " 'choice',\n",
       " 'thirty',\n",
       " 'fit',\n",
       " 'rooster',\n",
       " 'inbetween',\n",
       " 'may',\n",
       " 'beagles',\n",
       " 'system',\n",
       " 'podi',\n",
       " 'finance',\n",
       " 'house',\n",
       " 'for',\n",
       " 'something',\n",
       " 'palm',\n",
       " 'wrap',\n",
       " 'mm-hmm',\n",
       " 'same',\n",
       " 'favourite',\n",
       " 'he',\n",
       " 'by',\n",
       " 'coming',\n",
       " 'ahead',\n",
       " 'functionalities',\n",
       " 'functions',\n",
       " 'between',\n",
       " 'c_d_',\n",
       " 'ones',\n",
       " 'couple',\n",
       " 'who',\n",
       " 'it',\n",
       " 'big',\n",
       " 'languages',\n",
       " 'looking',\n",
       " 'not',\n",
       " 'emails',\n",
       " 'whale',\n",
       " 'top',\n",
       " 't_v_',\n",
       " 'design',\n",
       " 'head',\n",
       " 'whereas',\n",
       " 'styles',\n",
       " 'else',\n",
       " 'boy',\n",
       " 'ah',\n",
       " 'tail',\n",
       " 'twel',\n",
       " 'characteristics',\n",
       " 'television',\n",
       " 'everybody',\n",
       " 'd',\n",
       " 'some',\n",
       " 'finding',\n",
       " 'finish',\n",
       " 'so',\n",
       " 'process',\n",
       " 'goodness',\n",
       " 'original',\n",
       " 'gonna',\n",
       " 'to',\n",
       " 'primitive',\n",
       " 'pig',\n",
       " 'boards',\n",
       " 'mm',\n",
       " 'affection',\n",
       " 'no',\n",
       " 'home',\n",
       " 'lovely',\n",
       " 'twenty',\n",
       " 'functional',\n",
       " 'function',\n",
       " 'purchasing',\n",
       " 'gosh',\n",
       " 'mild',\n",
       " 'more',\n",
       " 'eat',\n",
       " 'of',\n",
       " 'useful',\n",
       " 'mean',\n",
       " 'fulfil',\n",
       " 'pilots',\n",
       " 'my',\n",
       " 'furry',\n",
       " 'couch',\n",
       " 'told',\n",
       " 'buy',\n",
       " 'worth',\n",
       " 'think',\n",
       " 'thank',\n",
       " 'kay',\n",
       " 'wee',\n",
       " 's',\n",
       " 'noise',\n",
       " \"he'll\",\n",
       " 'yourself',\n",
       " 'shelf',\n",
       " 'aye',\n",
       " 'user',\n",
       " 'executive',\n",
       " 'room',\n",
       " 'percent',\n",
       " 'times',\n",
       " 'planet',\n",
       " 'know',\n",
       " 'good',\n",
       " 'ok',\n",
       " 'allergic',\n",
       " 'market',\n",
       " 'designing',\n",
       " 'include',\n",
       " 'okay',\n",
       " 'cameras',\n",
       " 'mixture',\n",
       " \"people's\",\n",
       " 'into',\n",
       " 'interface',\n",
       " 'd_v_d_',\n",
       " 'individual',\n",
       " 'use',\n",
       " 'buttons',\n",
       " \"we'll\",\n",
       " 'just',\n",
       " 'working',\n",
       " 'gone',\n",
       " 'alright',\n",
       " 'actually',\n",
       " 'were',\n",
       " 'wholesale',\n",
       " 'great',\n",
       " 'away',\n",
       " \"he's\",\n",
       " 'fed',\n",
       " 'keeping',\n",
       " 'let',\n",
       " 'got',\n",
       " 'small',\n",
       " 'him',\n",
       " 'are',\n",
       " 'under',\n",
       " 'wonder',\n",
       " 'aiming',\n",
       " 'such',\n",
       " 'wel',\n",
       " \"we'd\",\n",
       " 'only',\n",
       " 'but',\n",
       " 'expert',\n",
       " 'might',\n",
       " 'guys',\n",
       " 'round',\n",
       " 'stuff',\n",
       " 'watch',\n",
       " 'together',\n",
       " 'nothing',\n",
       " \"they're\",\n",
       " \"isn't\",\n",
       " 'euros',\n",
       " 'never',\n",
       " 'real',\n",
       " 'pleased',\n",
       " 'days',\n",
       " 'kind',\n",
       " 'could',\n",
       " 'means',\n",
       " 'homes',\n",
       " 'what',\n",
       " 'four',\n",
       " 'feels',\n",
       " 'rush',\n",
       " 'thin',\n",
       " 'over',\n",
       " 'having',\n",
       " 'cause',\n",
       " 'parents',\n",
       " 'fact',\n",
       " 'one',\n",
       " 'tell',\n",
       " 'dinner',\n",
       " 'chic',\n",
       " 'announcement',\n",
       " 'given',\n",
       " 'record',\n",
       " 'cable',\n",
       " 'usually',\n",
       " 'message',\n",
       " 'repeat',\n",
       " 'physical',\n",
       " 'retail',\n",
       " 'lighting',\n",
       " 'w',\n",
       " 'cheery',\n",
       " 'reasonable',\n",
       " 'or',\n",
       " 'different',\n",
       " 'coffee',\n",
       " 'cram',\n",
       " 'part',\n",
       " 'sale',\n",
       " 'and',\n",
       " 'page',\n",
       " 'amusing',\n",
       " 'anyway',\n",
       " 'manager',\n",
       " 'telly',\n",
       " 'positioning',\n",
       " 'aim',\n",
       " 'up',\n",
       " 'features',\n",
       " 'when',\n",
       " 'regions',\n",
       " 'already',\n",
       " 'us',\n",
       " 'suggest',\n",
       " 'this',\n",
       " 'beep',\n",
       " 'time',\n",
       " 'after',\n",
       " \"wouldn't\",\n",
       " 'emailed',\n",
       " 'anything',\n",
       " 'uses',\n",
       " 'possibly',\n",
       " 'me',\n",
       " 'set',\n",
       " 'family',\n",
       " 'id',\n",
       " 'example',\n",
       " 'your',\n",
       " 'make',\n",
       " 'kicked',\n",
       " 'cool',\n",
       " 'how',\n",
       " \"one's\",\n",
       " 'y',\n",
       " 'combined',\n",
       " \"doesn't\",\n",
       " 'sets',\n",
       " 'successful',\n",
       " 'instructions',\n",
       " 'london',\n",
       " 'three',\n",
       " 'all',\n",
       " 'players',\n",
       " 'high',\n",
       " 'wealth',\n",
       " 'getting',\n",
       " 'scoot',\n",
       " 'write',\n",
       " 'scale',\n",
       " 'interesting',\n",
       " 'trendy',\n",
       " 'than',\n",
       " 'see',\n",
       " 'because',\n",
       " 'other',\n",
       " 'zones',\n",
       " 'sixteen',\n",
       " 'does',\n",
       " 'basic',\n",
       " 'cost',\n",
       " 'player',\n",
       " 'choose',\n",
       " 'whiteboard',\n",
       " 'new',\n",
       " 'sound',\n",
       " 'beyond',\n",
       " 'shoelaces',\n",
       " 'controls',\n",
       " 'take',\n",
       " 'you',\n",
       " 'guess',\n",
       " 'a',\n",
       " 'work',\n",
       " 'cute',\n",
       " 'sight',\n",
       " 'had',\n",
       " 'twelve',\n",
       " 'remote',\n",
       " 'everything',\n",
       " 'euro',\n",
       " 'product',\n",
       " \"didn't\",\n",
       " 'went',\n",
       " 'somethin',\n",
       " 'the',\n",
       " 'seventeen',\n",
       " 'becoming',\n",
       " 'robust',\n",
       " 'bearing',\n",
       " 'be',\n",
       " 'our',\n",
       " 'making',\n",
       " 'many',\n",
       " 'question',\n",
       " 'quite',\n",
       " 'from',\n",
       " 'things',\n",
       " 'blender',\n",
       " 'nicer',\n",
       " 'comes',\n",
       " 'b',\n",
       " 'table',\n",
       " 'need',\n",
       " 'appeal',\n",
       " 'touch',\n",
       " 'behind',\n",
       " 'attention',\n",
       " 'like',\n",
       " 'functionally',\n",
       " 'frequencies',\n",
       " 'keep',\n",
       " 'there',\n",
       " 'remember',\n",
       " 'going',\n",
       " 'can',\n",
       " 'spot',\n",
       " 'symbols',\n",
       " 'writing',\n",
       " 'audio',\n",
       " 'any',\n",
       " 'whatever',\n",
       " 'point',\n",
       " 'fish',\n",
       " 'why',\n",
       " 'put',\n",
       " 'five',\n",
       " 'devices',\n",
       " 'million',\n",
       " 'laura',\n",
       " 'always',\n",
       " 'now',\n",
       " 'whole',\n",
       " 'main',\n",
       " 'these',\n",
       " 'has',\n",
       " 'still',\n",
       " 'which',\n",
       " 'out',\n",
       " \"meeting's\",\n",
       " 'selling',\n",
       " 'most',\n",
       " 'sort',\n",
       " 'fur',\n",
       " 'here',\n",
       " 'would',\n",
       " 'anybody',\n",
       " 'his',\n",
       " 'where',\n",
       " 'whales',\n",
       " 'thinking',\n",
       " 'chara',\n",
       " 'arrived',\n",
       " 'apes',\n",
       " 'along',\n",
       " 'losing',\n",
       " 'v_c_r_',\n",
       " 'minutes',\n",
       " 'international',\n",
       " 'discussing',\n",
       " \"can't\",\n",
       " 'spend',\n",
       " 'david',\n",
       " 'imagine',\n",
       " 'conditioned',\n",
       " 'characteristic',\n",
       " 'factor',\n",
       " 'way',\n",
       " 'gear',\n",
       " 'internationally',\n",
       " 'sell',\n",
       " 'funny',\n",
       " 'extra',\n",
       " 'assess',\n",
       " 'affectionate',\n",
       " 'cap',\n",
       " 'ten',\n",
       " 'sure',\n",
       " 'sooner',\n",
       " 'friendly',\n",
       " 'thi',\n",
       " 'we',\n",
       " 'willing',\n",
       " 'an',\n",
       " 'project',\n",
       " 'technical',\n",
       " 'off',\n",
       " 'wants',\n",
       " 'wanna',\n",
       " 'check',\n",
       " 'lot',\n",
       " 'stage',\n",
       " 'consciously',\n",
       " 'various',\n",
       " 'well',\n",
       " 'keypad',\n",
       " 'screen',\n",
       " 'complicated',\n",
       " 'machine',\n",
       " 'uh',\n",
       " 'if',\n",
       " 'sketch',\n",
       " 'been',\n",
       " 'thought',\n",
       " 'have',\n",
       " \"that's\",\n",
       " 'm',\n",
       " 'priorities',\n",
       " \"it's\",\n",
       " 'brief',\n",
       " 'before',\n",
       " 'designer',\n",
       " 'first',\n",
       " 'another',\n",
       " \"there's\",\n",
       " \"they've\",\n",
       " \"we're\",\n",
       " 'kinda',\n",
       " 'compares',\n",
       " 'actual',\n",
       " 'money',\n",
       " \"it'll\",\n",
       " 'sense',\n",
       " 'yes',\n",
       " 'ironic',\n",
       " 'coulda',\n",
       " 'then',\n",
       " 'try',\n",
       " 'exploring',\n",
       " 'lots',\n",
       " 'at',\n",
       " 'i',\n",
       " 'requirements',\n",
       " 'materials',\n",
       " 'their',\n",
       " 'according',\n",
       " 'should',\n",
       " 'hmm',\n",
       " 'end',\n",
       " 'say',\n",
       " 'very',\n",
       " 'add',\n",
       " 'streamlined',\n",
       " 'awful',\n",
       " 'mine',\n",
       " 'long',\n",
       " \"i'll\",\n",
       " \"you're\",\n",
       " 'was',\n",
       " 'on',\n",
       " 'producing',\n",
       " 'monkey',\n",
       " 'assumptions',\n",
       " 'production',\n",
       " \"i'm\",\n",
       " 'kick-off',\n",
       " 'go',\n",
       " 'feel',\n",
       " 'al',\n",
       " 'shoes',\n",
       " 'as',\n",
       " 'marketing',\n",
       " 'notes',\n",
       " 'commitment',\n",
       " 'little',\n",
       " 'cha',\n",
       " 'beagle',\n",
       " 'with',\n",
       " 'probably',\n",
       " 'r',\n",
       " 'european',\n",
       " 'quickly',\n",
       " 'p',\n",
       " 'ach',\n",
       " 'massive',\n",
       " 'that',\n",
       " 'in',\n",
       " 'meeting',\n",
       " 'nice',\n",
       " \"manufacturer's\",\n",
       " 'god',\n",
       " 'about',\n",
       " 'is',\n",
       " 'heavier',\n",
       " 'talking',\n",
       " 'too',\n",
       " 'chat',\n",
       " 'funct',\n",
       " 'require',\n",
       " 'slightly',\n",
       " 'panel',\n",
       " 'implemented',\n",
       " 'reach',\n",
       " 'restriction',\n",
       " 'traditional',\n",
       " 'required',\n",
       " 'suppose',\n",
       " 'blue',\n",
       " 'apart',\n",
       " 'categories',\n",
       " 'technologically',\n",
       " \"who's\",\n",
       " 'own',\n",
       " 'seem',\n",
       " 'right',\n",
       " 'regular',\n",
       " 'option',\n",
       " 'restrict',\n",
       " 'separating',\n",
       " 'half',\n",
       " 'components',\n",
       " 'next',\n",
       " 'each',\n",
       " 'discuss',\n",
       " 'notepad',\n",
       " \"you'll\",\n",
       " 'terms',\n",
       " \"they'll\",\n",
       " 'words',\n",
       " 'quid',\n",
       " \"we've\",\n",
       " 'confirm',\n",
       " 'target',\n",
       " 'information',\n",
       " 'goes',\n",
       " 'speech',\n",
       " 'since',\n",
       " 'categorise',\n",
       " 'thing',\n",
       " 'consume',\n",
       " 'picture',\n",
       " 'agree',\n",
       " 'far',\n",
       " 'needed',\n",
       " 'technology',\n",
       " 'front',\n",
       " 'also',\n",
       " \"what's\",\n",
       " 'started',\n",
       " 'looked',\n",
       " 'n',\n",
       " \"david's\",\n",
       " 'they',\n",
       " 'lost',\n",
       " 'uh-huh',\n",
       " 'confine',\n",
       " 'yeah',\n",
       " 'fresh',\n",
       " 'exactly',\n",
       " 'piece',\n",
       " 'homepage',\n",
       " 'voice',\n",
       " 'did',\n",
       " 'simple',\n",
       " 'start',\n",
       " 'supposed',\n",
       " 'break',\n",
       " 'lives',\n",
       " 'created',\n",
       " 'control',\n",
       " 'oh',\n",
       " 'even',\n",
       " 'overall',\n",
       " 'though',\n",
       " \"aren't\",\n",
       " 'expensive',\n",
       " 'video',\n",
       " 'prepared',\n",
       " 'creative',\n",
       " 'although',\n",
       " 'th',\n",
       " 'indication',\n",
       " 'view',\n",
       " 'certain',\n",
       " 'suggested',\n",
       " 'simplest',\n",
       " 'again',\n",
       " 'outside',\n",
       " 'perg',\n",
       " 'colours',\n",
       " 'shapes',\n",
       " 'forty-ish',\n",
       " \"t_v_'s\",\n",
       " 'recurring',\n",
       " 'doing',\n",
       " 'standard',\n",
       " 'categorising',\n",
       " 'either',\n",
       " 'slow',\n",
       " 'suspect',\n",
       " 'dunno',\n",
       " 'being',\n",
       " 'putting',\n",
       " 'skip',\n",
       " 'occurred',\n",
       " 'punch',\n",
       " 'pick',\n",
       " 'groups',\n",
       " 'outdated',\n",
       " 'come',\n",
       " 'looks',\n",
       " \"i'd\",\n",
       " 'really',\n",
       " 'simpleness',\n",
       " 'universities',\n",
       " \"somebody's\",\n",
       " 'website',\n",
       " 'down',\n",
       " 'users',\n",
       " 'sleek',\n",
       " 'identifying',\n",
       " 'motion',\n",
       " 'helps',\n",
       " 'mating',\n",
       " 'yellow',\n",
       " 'bout',\n",
       " 'deciding',\n",
       " 'chair',\n",
       " 'yep',\n",
       " 'tend',\n",
       " 'trend',\n",
       " 'watching',\n",
       " 'get',\n",
       " 'easily',\n",
       " \"let's\",\n",
       " 'f',\n",
       " 'will',\n",
       " \"company's\",\n",
       " 'natural',\n",
       " 'happy',\n",
       " 'craig',\n",
       " 'industrial',\n",
       " 'technologies',\n",
       " 'maybe',\n",
       " 'sh',\n",
       " 'much',\n",
       " 'button',\n",
       " 'keyboard',\n",
       " 'want',\n",
       " 'colour',\n",
       " 'cradle',\n",
       " 'hi',\n",
       " 'um',\n",
       " 'instance',\n",
       " 'steps',\n",
       " 'steal',\n",
       " 'fewer',\n",
       " 'andrew',\n",
       " 'slide',\n",
       " 'ma',\n",
       " 'represents',\n",
       " \"haven't\",\n",
       " 'ideas',\n",
       " 'yo',\n",
       " 'simpler',\n",
       " 'channel',\n",
       " 'people',\n",
       " 'primarily',\n",
       " 'them',\n",
       " 'picked',\n",
       " 'becomes',\n",
       " 'wondering',\n",
       " 'do',\n",
       " 'find',\n",
       " 'left',\n",
       " \"i've\",\n",
       " 'affect',\n",
       " 'discussion',\n",
       " 'practical',\n",
       " 'better',\n",
       " 'mobile',\n",
       " 'smile',\n",
       " 'embody',\n",
       " 'used',\n",
       " 'r_s_i_',\n",
       " 'narrowed',\n",
       " 'fits',\n",
       " 'price',\n",
       " 'habits',\n",
       " 'done',\n",
       " 'places',\n",
       " 'transmit',\n",
       " 'blocks',\n",
       " 'second',\n",
       " 'allowed',\n",
       " 'bit',\n",
       " \"don't\",\n",
       " 'pounds',\n",
       " 'portion',\n",
       " 'products',\n",
       " 'idea',\n",
       " 'basically',\n",
       " 'touches',\n",
       " 'internet',\n",
       " 'run',\n",
       " 'those',\n",
       " 'incredibly',\n",
       " 'input',\n",
       " 'less',\n",
       " \"everybody's\",\n",
       " 'cr',\n",
       " 'parts',\n",
       " 'look',\n",
       " 'decide',\n",
       " 'choice',\n",
       " 'thirty',\n",
       " 'lo',\n",
       " 'charge',\n",
       " 'fit',\n",
       " 'standing',\n",
       " 'may',\n",
       " 'expecting',\n",
       " 'across',\n",
       " 'push',\n",
       " 'for',\n",
       " 'change',\n",
       " 'quirky',\n",
       " 'something',\n",
       " 'within',\n",
       " 'wrap',\n",
       " 'mm-hmm',\n",
       " 'shy',\n",
       " 'individually',\n",
       " 'activate',\n",
       " 'worthwhile',\n",
       " 'same',\n",
       " 'separate',\n",
       " 'pieces',\n",
       " 'component',\n",
       " 'telling',\n",
       " 'spread',\n",
       " 'role',\n",
       " 'by',\n",
       " 'fair',\n",
       " 'showing',\n",
       " 'size',\n",
       " 'define',\n",
       " 'wanted',\n",
       " 'recognition',\n",
       " 'nobody',\n",
       " 'select',\n",
       " 'side',\n",
       " 'besides',\n",
       " 'read',\n",
       " 'ahead',\n",
       " 'functions',\n",
       " 'particular',\n",
       " 'between',\n",
       " 'took',\n",
       " 'line',\n",
       " 'later',\n",
       " 'obviously',\n",
       " 'vast',\n",
       " 'frequency',\n",
       " 'ones',\n",
       " 'couple',\n",
       " 'who',\n",
       " 'it',\n",
       " 'came',\n",
       " 'clarification',\n",
       " 'big',\n",
       " 'looking',\n",
       " 'not',\n",
       " 'oop',\n",
       " 't_v_',\n",
       " 'top',\n",
       " 'vision',\n",
       " 'design',\n",
       " 'nope',\n",
       " 'styles',\n",
       " 'else',\n",
       " 'bad',\n",
       " 'please',\n",
       " 'schools',\n",
       " 'hours',\n",
       " 'microphone',\n",
       " 'complex',\n",
       " 'constraint',\n",
       " 'dislike',\n",
       " 'television',\n",
       " 'em',\n",
       " 'everybody',\n",
       " 'customer',\n",
       " 'd',\n",
       " 'some',\n",
       " 'fifteen',\n",
       " 'finding',\n",
       " 'finish',\n",
       " 'visualisation',\n",
       " 'completely',\n",
       " 'build',\n",
       " 'so',\n",
       " 'mention',\n",
       " 'high-tech',\n",
       " 'teletext',\n",
       " 'process',\n",
       " 'blink',\n",
       " 'picks',\n",
       " 'hopefully',\n",
       " 'gonna',\n",
       " 'few',\n",
       " 'to',\n",
       " 'eliminate',\n",
       " 'said',\n",
       " 'primitive',\n",
       " 'able',\n",
       " 'mm',\n",
       " 'acc',\n",
       " 'entirely',\n",
       " 'rough',\n",
       " \"wasn't\",\n",
       " 'device',\n",
       " 'needs',\n",
       " 'no',\n",
       " 'previously',\n",
       " 'signal',\n",
       " 'plug',\n",
       " 'advances',\n",
       " 'functional',\n",
       " 'twenty',\n",
       " 'presentations',\n",
       " 'consider',\n",
       " 'click',\n",
       " 'function',\n",
       " 'mid',\n",
       " 'gives',\n",
       " \"controller's\",\n",
       " 'installing',\n",
       " 'more',\n",
       " 'decision',\n",
       " 'relay',\n",
       " 'two',\n",
       " 'prog',\n",
       " 'saying',\n",
       " 'optional',\n",
       " 'knot',\n",
       " 'impacts',\n",
       " 'of',\n",
       " 'disagree',\n",
       " 'f_',\n",
       " 'wire',\n",
       " 'specific',\n",
       " 'existing',\n",
       " 'mean',\n",
       " 'fulfil',\n",
       " 'series',\n",
       " 'my',\n",
       " 'give',\n",
       " 'controller',\n",
       " 'couch',\n",
       " 'buy',\n",
       " 'told',\n",
       " 'worth',\n",
       " 'think',\n",
       " 'absolutely',\n",
       " 'income',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list = []\n",
    "for xfile in os.listdir(txt_file_path):\n",
    "    xfile = os.path.join(txt_file_path, xfile)\n",
    "    if os.path.isfile(xfile) and xfile.endswith('.txt'): \n",
    "        all_list += main(xfile)\n",
    "# len(all_list)\n",
    "all_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the stop words lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the stop words lists\n",
    "stop_file = open(\"stopwords_en.txt\", \"r\")\n",
    "stop_list = stop_file.read().split('\\n')\n",
    "# stop_file.close() at the end of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove all stop words\n",
    "stop_set = set(stop_list)\n",
    "stopped_tokens = [ww for ww in all_list if ww not in stop_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all words whose length less than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all words whose length less than 3\n",
    "new_tokens = [w for w in stopped_tokens if len(w) >2]\n",
    "# len(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove words whose frequencies is larger than 132 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words whose frequencies is larger than 132 \n",
    "wordfreq = []\n",
    "fdist = FreqDist(all_list)   \n",
    "for v in new_tokens:\n",
    "    if fdist[v] <= 132:\n",
    "        wordfreq.append(v)\n",
    "# sorted(fdist.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordfreq = sorted(set(wordfreq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final vocab list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = ['{0}:{1}'.format(i, wordfreq.index(i)) for i in wordfreq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write file\n",
    "vocab = open(\"vocab.txt\",\"w\")\n",
    "vocab_str = \"\\n\".join(final_list)\n",
    "vocab.write(vocab_str)\n",
    "vocab.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary for store vocab and index\n",
    "vocab_dic = dict()\n",
    "for ii in wordfreq:\n",
    "    vocab_dic[ii] = wordfreq.index(ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Topic_seg\n",
    "\n",
    "Assumption: I assumed that \"after being preprocessed\" means preprocessed in task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg(txt):\n",
    "    txt_file = open(txt, \"r\")\n",
    "    l = []# list for storing boolean number\n",
    "    for line in txt_file.readlines():\n",
    "        if line[0] == ' ':# start with a space append \"0\"\n",
    "            l.append(0)\n",
    "        if line[0] == '*': # start with \"*\" append \"1\" at the previous line\n",
    "            l[-1] = 1\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_topic = \"\"\n",
    "for xfile in os.listdir(txt_file_path):\n",
    "    if xfile.endswith('.txt'):\n",
    "        # get file name\n",
    "        x = re.findall(r'\\w{2}\\d{4}\\w{1}|\\w{2}\\d{4}', xfile)[0]\n",
    "\n",
    "    one_topic = \"\"\n",
    "    xfile = os.path.join(txt_file_path, xfile)\n",
    "    if os.path.isfile(xfile) and xfile.endswith('.txt'): \n",
    "        for se in seg(xfile):\n",
    "            one_topic += str(se) + \",\"\n",
    "\n",
    "        _topic += x +\":\"+ one_topic[0:-1] +'\\n'\n",
    "_topic = _topic[0:-1]\n",
    "\n",
    "topic_segs = open(\"topic_segs.txt\",\"w\")\n",
    "topic_segs.write(_topic)\n",
    "topic_segs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sparse_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'count' function for count frequency\n",
    "def count(arr):\n",
    "    count = dict()\n",
    "    for w in arr:\n",
    "        if w in count:\n",
    "            count[w] += 1\n",
    "        else:\n",
    "            count[w] = 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse function for generating corresponding sparse file\n",
    "Format :$index:frequency$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sparse(txt):\n",
    "    txt_file = open(txt, \"r\")\n",
    "    file_list = [] # whole file list\n",
    "    for line in txt_file.readlines():\n",
    "        file_token = []\n",
    "        line = line.strip().lower()            \n",
    "        token_list = tokenizer.tokenize(line)# each line in text file and store as a list\n",
    "\n",
    "        for t in token_list:\n",
    "            if t in vocab_dic:\n",
    "                # corresponding index : frequency\n",
    "                file_token.append(str(vocab_dic[t])+\":\"+ str(count(token_list)[t]))\n",
    "        # delete empty list\n",
    "        if file_token != []:\n",
    "            tep_list = list(set(file_token))\n",
    "            tep_list.sort(key=file_token.index)\n",
    "            \n",
    "            file_list.append(tep_list)\n",
    "\n",
    "    return(file_list)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use sparse function to generate all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final output\n",
    "for xfile in os.listdir(txt_file_path):\n",
    "    if xfile.endswith('.txt'):\n",
    "        x = xfile\n",
    "    xfile = os.path.join(txt_file_path, xfile)\n",
    "    if os.path.isfile(xfile) and xfile.endswith('.txt'): \n",
    "        seg_list = sparse(xfile)\n",
    "        str2 = \"\"\n",
    "        for item in seg_list:\n",
    "            str1 = \"\"\n",
    "            for i in item:\n",
    "                str1 = str1+i + \",\"\n",
    "                \n",
    "            str1 = str1[0:-1]\n",
    "            str2 += str1 +\"\\n\"\n",
    "        str2 = str2[0:-1]\n",
    "        # write file\n",
    "        thefile = open(\"sparse_files/\"+x,\"w\")\n",
    "        thefile.write(str2)\n",
    "        thefile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

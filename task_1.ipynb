{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Reconstruct the Original Meeting Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name: Xiaofan Zhang\n",
    "#### Student ID: 28338707\n",
    "\n",
    "Date: 03/06/2018\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include the main libraries you used in your assignment here, e.g.,: \n",
    "* re \n",
    "* os\n",
    "* xml.etree.ElementTree \n",
    "\n",
    "Running Times:\n",
    "It needs at least 20 mins to run all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree \n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_path = \"./topics\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Function for creating dict{topic: corresponding word file name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function for create dict{topic: corresponding word file name}\n",
    "def getDic(x):\n",
    "    topic = \"\"\n",
    "    allList = []\n",
    "    \n",
    "    topic_file = xml.etree.ElementTree.parse(x)\n",
    "    topic_root = topic_file.getroot()\n",
    "    for child in topic_root:\n",
    "        allIn = {}\n",
    "        # topic name \n",
    "        topic = child.attrib[list(child.attrib.keys())[0]]\n",
    "        word_id = []\n",
    "        # get all child include sub-topic\n",
    "        for c in child.iter():\n",
    "            if list(c.attrib.keys())[0] == 'href':\n",
    "                ca = c.attrib['href']\n",
    "                pattern_word = re.compile(r'(\\w{2}\\d{4}\\w{1}.\\w{1}.words|\\w{2}\\d{4}.\\w{1}.words).xml')\n",
    "                word_id += (pattern_word.findall(ca))\n",
    "            # topic name as key and word file name as value\n",
    "            allIn= {topic : word_id}\n",
    "        allList.append(allIn)\n",
    "    return(allList)\n",
    "\n",
    "# save all dictionary in a list\n",
    "xml_file_path = \"./topics\"\n",
    "listDix = []\n",
    "for xfile in os.listdir(xml_file_path): \n",
    "    listDix.append(getDic(\"topics/\"+ xfile))\n",
    "    \n",
    "lists = listDix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Function for creating dict{topic: corresponding word file text boundaries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for create dict{topic: corresponding word file text boundaries}\n",
    "def getDicste(x):\n",
    "    topic = \"\"\n",
    "    allList = []\n",
    "    \n",
    "    topic_file = xml.etree.ElementTree.parse(x)\n",
    "    topic_root = topic_file.getroot()\n",
    "    \n",
    "    for child in topic_root:\n",
    "        allIn = {}\n",
    "        topic = child.attrib[list(child.attrib.keys())[0]]\n",
    "        word_ste1 = []\n",
    "        # get all child include sub-topic\n",
    "        for c in child.iter():\n",
    "            if list(c.attrib.keys())[0] == 'href':\n",
    "                ca = c.attrib['href']\n",
    "                word_num = re.compile(r'words(\\d{1,})')\n",
    "                word_ste1.append(word_num.findall(ca))\n",
    "        \n",
    "        # topic name as key and word file boundaries as value\n",
    "        allIn= {topic : word_ste1}\n",
    "        allList.append(allIn)\n",
    "    return(allList)\n",
    "# save all dictionary in a list\n",
    "listDicste = []\n",
    "for xfile in os.listdir(xml_file_path): \n",
    "    listDicste.append(getDicste(\"topics/\"+ xfile))\n",
    "    \n",
    "lists1 = listDicste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Function for generating corresponding segment boundaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating dic{segment : corresponding segment boundaries}\n",
    "# seg_file_path = \"./segments\"\n",
    "def getSefNum(x):\n",
    "    file = xml.etree.ElementTree.parse(x)\n",
    "    root = file.getroot()\n",
    "    seg = []\n",
    "    word_name1 = []\n",
    "    for segment in root:\n",
    "        for child in segment.findall(\"{http://nite.sourceforge.net/}child\"):\n",
    "            child_attr = child.attrib['href']\n",
    "            seg_pos = re.compile(r'(\\w{2}\\d{4}\\w.\\w.words\\d{1,}|\\w{2}\\d{4}.\\w{1}.words\\d{1,})')\n",
    "            seg.append(seg_pos.findall(child_attr))\n",
    "            \n",
    "    return (seg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Combine two topic dictionaries with segment and generate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for atopic in range(len(lists)):\n",
    "    # topic file name for generate file\n",
    "    file_obj = re.findall(r\"(\\w{2}\\d{4}\\w{1}|\\w{2}\\d{4}).topic\",list(lists[atopic][0].keys())[0])[0]\n",
    "\n",
    "    _str = []\n",
    "    for l in range(len(lists[atopic])):\n",
    "        values = list(lists[atopic][l].values())[0] # list of str 'ES2002a.B.words'\n",
    "        num = list(lists1[atopic][l].values())[0]# list of lists\n",
    "        word_str = \"\"\n",
    "        for v in range(len(values)):\n",
    "            seg_list = []\n",
    "            wfile = xml.etree.ElementTree.parse(\"words/\" + values[v] + \".xml\").getroot()\n",
    "            \n",
    "            seg_list1 = \"\"\n",
    "            seg_list1 = getSefNum(\"segments/\" + re.findall(r\"(\\w{2}\\d{4}\\w{1}.\\w{1}|\\w{2}\\d{4}.\\w{1})\", values[v])[0] + \".segments.xml\")# seg_list1\n",
    "            for k in seg_list1:\n",
    "                seg_list.append(k[-1])# only get the last number of segments for add \"\\n\"\n",
    "            for word in wfile.getchildren():\n",
    "                if len(num[v]) == 2:# two words range e.g.[0,71]\n",
    "                    if word.attrib['{http://nite.sourceforge.net/}id'] in list(values[v] + str(i) for i in range(int(num[v][0]), int(num[v][1])+1)):\n",
    "                        if word.attrib['{http://nite.sourceforge.net/}id'] in seg_list: \n",
    "                            if word.text is None:# ignore vocalsound but segment\n",
    "                                word_str += \"\\n\"\n",
    "                            else:\n",
    "                                word_str += \" \" + word.text+ \"\\n\"\n",
    "                        else:\n",
    "                            if word.text is None:\n",
    "                                pass\n",
    "                            else:                \n",
    "                                word_str += \" \" + word.text\n",
    "                else: # one words range e.g.[72]\n",
    "                    if word.attrib['{http://nite.sourceforge.net/}id'] in list(values[v] + str(i) for i in range(int(num[v][0]), int(num[v][0])+1)):\n",
    "                        if word.attrib['{http://nite.sourceforge.net/}id'] in seg_list: \n",
    "                            if word.text is None:\n",
    "                                word_str += \"\\n\"\n",
    "                            else:\n",
    "                                word_str += \" \" + word.text+ \"\\n\"\n",
    "                        else:\n",
    "                            if word.text is None:\n",
    "                                pass\n",
    "                            else: \n",
    "                                word_str += \" \" + word.text\n",
    "            \n",
    "            word_str = word_str+\"\\n\"\n",
    "                \n",
    "        word_str = word_str+\"\\n\"\n",
    "        # delete any empty lines\n",
    "        word_str = word_str.replace('\\n\\n\\n\\n\\n\\n', '\\n')                    \n",
    "        word_str = word_str.replace('\\n\\n\\n\\n\\n', '\\n')                    \n",
    "        word_str = word_str.replace('\\n\\n\\n\\n', '\\n')                    \n",
    "        word_str = word_str.replace('\\n\\n\\n', '\\n')\n",
    "        word_str = word_str.replace('\\n\\n', '\\n')\n",
    "        if word_str[0] == \"\\n\":\n",
    "            word_str = word_str[1:]\n",
    "\n",
    "       \n",
    "        _str.append(word_str)\n",
    "        a = \"\"\n",
    "        # add topical boundries\n",
    "        a= \"**********\\n\".join(_str) + \"**********\"\n",
    "\n",
    "    \n",
    "    file = open(\"txt_files3/\"+file_obj+\".txt\",\"w\")\n",
    "    file.write(a)\n",
    "    file.close()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
